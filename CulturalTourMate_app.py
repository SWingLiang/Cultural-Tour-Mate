import streamlit as st
import google.generativeai as genai
import dotenv
import os
import mimetypes
from PIL import Image
from google.generativeai.types.content_types import Part

# ========== é¡µé¢é…ç½® ==========
st.set_page_config(page_title="Cultural-Tour-Mate", layout="centered")

# ========== åŠ è½½ API Key ==========
dotenv.load_dotenv()
api_key = os.getenv("API_KEY")
genai.configure(api_key=api_key)

# ========== å¤šè¯­è¨€æ”¯æŒ ==========
translations = {
    "en": {
        "title": "ğŸ›ï¸Cultural-Tour-Mate",
        "slogan": "Your trustworthy, insightful, and articulate cultural companion in tour.",
        "upload": "ğŸ–¼ï¸ Upload Image",
        "camera": "ğŸ“· Capture Photo",
        "camera_on": "ğŸ“¸ Take a shot",
        "camera_sub": "Any cultural troubles during the tour, please take a photo and ask me.",
        "desc": "Describe what you want to learn about the image:",
        "ask": "SendğŸ¦„",
        "response": "Cultural Insight",
        "feedback": "Was this helpful? Feel free to ask more.",
        "developer": "Developer: Xianrong Liang (Sinwing); Abhay Soni; Shayan Majid Phamba; Gurjot Singh.",
        "upload_note": "Select and upload an image from your device, the image is limited to 200 MB.",
        "camera_note": "Due to technical limitations, only the front camera is supported. Suggest upload photos.",
        "input_placeholder": "Type your question here...",
        "user_role": "ğŸ’¬Ask"
    },
    "zh": {
        "title": "ğŸ›ï¸AIæ–‡åŒ–æ—…ä¼´",
        "slogan": "æ‚¨å¿ å®åšå­¦ä¸”æ™ºæ…§çš„æ–‡åŒ–æ—…è¡Œå°ä¼™ä¼´ã€‚",
        "upload": "ğŸ–¼ï¸ ä¸Šä¼ å›¾åƒ",
        "camera": "ğŸ“· ç°åœºæ‹ç…§",
        "camera_on": "ğŸ“¸ æ‰“å¼€ç›¸æœº",
        "camera_sub": "æ—…é€”ä¸­çš„æ–‡åŒ–å›°æ‰°ï¼Œè¯·éšæ‰‹æ‹ä¸€å¼ ç…§ç‰‡é—®é—®æˆ‘ã€‚",
        "desc": "æè¿°æ‚¨æƒ³äº†è§£çš„å›¾åƒå†…å®¹ï¼š",
        "ask": "å‘é€ğŸ¦„",
        "response": "æ–‡åŒ–èƒŒæ™¯ä¿¡æ¯",
        "feedback": "è¿™ä¸ªå›ç­”æœ‰å¸®åŠ©å—ï¼Ÿæ¬¢è¿ç»§ç»­æé—®ã€‚",
        "developer": "å¼€å‘è€…ï¼šæ¢ç¾¡è£(Sinwing); Abhay Soni; Shayan Majid Phamba; Gurjot Singh",
        "upload_note": "ä»æ‚¨çš„è®¾å¤‡ä¸­é€‰æ‹©å¹¶ä¸Šä¼ ä¸€å¼ å›¾ç‰‡ï¼Œå¤§å°ä¸è¶…è¿‡200Mã€‚",
        "camera_note": "ç”±äºæŠ€æœ¯é™åˆ¶ï¼Œç›®å‰ä»…æ”¯æŒå‰ç½®æ‘„åƒå¤´ï¼Œå»ºè®®ä¸Šä¼ ç…§ç‰‡ã€‚",
        "input_placeholder": "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...",
        "user_role": "ğŸ’¬è¯·é—®"
    }
}

# ========== è¯­è¨€é€‰æ‹© ==========
language = st.selectbox("ğŸŒ Select Language EN/CN | æ”¯æŒä¸­è‹±æ–‡", ["English", "ä¸­æ–‡"])
lang_map = {"English": "en", "ä¸­æ–‡": "zh"}
lang_code = lang_map[language]
t = translations[lang_code]

# ========== Avatar å›¾åƒ ==========
avatar_urls = {
    "en": "https://static.vecteezy.com/system/resources/previews/055/495/027/non_2x/a-man-in-a-white-t-shirt-and-jeans-free-png.png",
    "zh": "https://static.vecteezy.com/system/resources/previews/013/167/583/original/portrait-of-a-smiling-asian-woman-cutout-file-png.png",
}
avatar_url = avatar_urls.get(lang_code, '')

# ========== Avatar èƒŒæ™¯æ ·å¼ ==========
if avatar_url:
    st.markdown(f"""
    <style>
    .avatar-bg {{
        position: fixed;
        bottom: 0px;
        left: 10px;
        height: 45vh;
        opacity: 0.5;
        z-index: 0;
    }}
    @media (max-width: 768px) {{
        .avatar-bg {{
            display: none;
        }}
    }}
    </style>
    <img class="avatar-bg" src="{avatar_url}" />
    """, unsafe_allow_html=True)

# ========== æ ‡é¢˜ä¸è¯´æ˜ ==========
st.title(t["title"])
st.markdown(t["slogan"])
st.caption(t["developer"])

# ========== åˆå§‹åŒ–ä¼šè¯ ==========
def fetch_conversation_history():
    if "messages" not in st.session_state:
        st.session_state["messages"] = [
            {
                "role": "user",
                "parts": "system prompt: You are CulturalTourMateï¼Œa trustworthy, insightful, and articulate cultural companion. When a tourist uploads or captures an image of a landmark, artifact, or artwork, you provide engaging, accurate, and culturally rich information to deepen their understanding. You explain historical context, symbolism, artistic style, and local significance in a concise yet refined way. Your tone is friendly, professional, and easy to understand, empowering travelers to connect meaningfully with the cultures they encounter."
            }
        ]
    return st.session_state["messages"]

# ========== Gemini å›å¤ ==========
def generate_reply(messages, user_input, image_part=None):
    try:
        model = genai.GenerativeModel("gemini-pro-vision")
        chat = model.start_chat(history=messages)

        if image_part:
            image_part_obj = Part.from_data(
                data=image_part["data"],
                mime_type=image_part["mime_type"]
            )
            response = chat.send_message([user_input, image_part_obj])
        else:
            response = chat.send_message(user_input)

        return response
    except Exception as e:
        import traceback
        st.error("âš ï¸ Gemini API request failed. Check your network or API Key.")
        st.text_area("Error details", traceback.format_exc(), height=200)
        return str(e)

# ========== ä¸Šä¼ ä¸æ‹ç…§ ==========

image = None
image_part = None

# æ‹ç…§
st.markdown("### " + t["camera"])
st.markdown(t["camera_sub"])
st.caption(t["camera_note"])
if st.button(t["camera_on"]):
    camera_image = st.camera_input("")
    if camera_image:
        image = Image.open(camera_image)
        image_part = {
            "mime_type": "image/jpeg",
            "data": camera_image.getvalue()
        }

st.markdown("---")

# ä¸Šä¼ 
st.markdown("### " + t["upload"])
uploaded_image = st.file_uploader(t["upload_note"], type=["jpg", "jpeg", "png"])
if uploaded_image:
    image = Image.open(uploaded_image)
    mime_type, _ = mimetypes.guess_type(uploaded_image.name)
    image_part = {
        "mime_type": mime_type or "image/jpeg",
        "data": uploaded_image.getvalue()
    }

if image:
    st.image(image, caption="Selected Image", use_container_width=True)

# ========== ç”¨æˆ·æé—® ==========
st.markdown("---")
st.markdown("### " + t["user_role"])
user_input = st.text_input(" ", placeholder=t["input_placeholder"], key="text_input")

if st.button(t["ask"]):
    if user_input:
        messages = fetch_conversation_history()
        messages.append({"role": "user", "parts": user_input})
        with st.spinner("Processing..."):
            response = generate_reply(messages, user_input, image_part)

        if isinstance(response, str):
            st.error(response)
        else:
            bot_reply = response.candidates[0].content.parts[0].text
            messages.append({"role": "model", "parts": bot_reply})
            st.session_state["messages"] = messages

# ========== å¯¹è¯å†å² ==========
st.markdown("---")
st.subheader("ğŸ—¨ï¸ Conversation History")

if "messages" in st.session_state:
    for message in st.session_state["messages"]:
        if "system prompt" in message["parts"]:
            continue
        if message["role"] == "user":
            st.markdown(
                f"<div style='text-align:right; padding: 8px 12px; background-color:#e6f7ff; border-radius:10px; margin-bottom:8px;'>{message['parts']}</div>",
                unsafe_allow_html=True
            )
        elif message["role"] == "model":
            st.markdown(
                f"<div style='display:flex; align-items:center; margin-bottom:8px;'><img src='{avatar_urls[lang_code]}' width='40' style='margin-right:10px;'><div style='background-color:#f5f5f5; padding:8px 12px; border-radius:10px;'>{message['parts']}</div></div>",
                unsafe_allow_html=True
            )
